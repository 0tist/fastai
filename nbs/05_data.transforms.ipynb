{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp data.transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from fastai2.torch_basics import *\n",
    "from fastai2.data.core import *\n",
    "from fastai2.data.load import *\n",
    "from fastai2.data.external import *\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper functions for processing data and basic transforms\n",
    "\n",
    "> Functions for getting, splitting, and labeling data, as well as generic transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get, split, and label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For most data source creation we need functions to get a list of items, split them in to train/valid sets, and label them. fastai provides functions to make each of these steps easy (especially when combined with `fastai.data.blocks`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we'll look at functions that *get* a list of items (generally file names).\n",
    "\n",
    "We'll use *tiny MNIST* (a subset of MNIST with just two classes, `7`s and `3`s) for our examples/tests throughout this page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#2) [Path('/root/.fastai/data/mnist_tiny/train/7'),Path('/root/.fastai/data/mnist_tiny/train/3')]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = untar_data(URLs.MNIST_TINY)\n",
    "(path/'train').ls()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def _get_files(p, fs, extensions=None):\n",
    "    p = Path(p)\n",
    "    res = [p/f for f in fs if not f.startswith('.')\n",
    "           and ((not extensions) or f'.{f.split(\".\")[-1].lower()}' in extensions)]\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def get_files(path, extensions=None, recurse=True, folders=None):\n",
    "    \"Get all the files in `path` with optional `extensions`, optionally with `recurse`, only in `folders`, if specified.\"\n",
    "    path = Path(path)\n",
    "    folders=L(folders)\n",
    "    extensions = setify(extensions)\n",
    "    extensions = {e.lower() for e in extensions}\n",
    "    if recurse:\n",
    "        res = []\n",
    "        for i,(p,d,f) in enumerate(os.walk(path)): # returns (dirpath, dirnames, filenames)\n",
    "            if len(folders) !=0 and i==0: d[:] = [o for o in d if o in folders]\n",
    "            else:                         d[:] = [o for o in d if not o.startswith('.')]\n",
    "            if len(folders) !=0 and i==0 and '.' not in folders: continue\n",
    "            res += _get_files(p, f, extensions)\n",
    "    else:\n",
    "        f = [o.name for o in os.scandir(path) if o.is_file()]\n",
    "        res = _get_files(path, f, extensions)\n",
    "    return L(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the most general way to grab a bunch of file names from disk. If you pass `extensions` (including the `.`) then returned file names are filtered by that list. Only those files directly in `path` are included, unless you pass `recurse`, in which case all child folders are also searched recursively. `folders` is an optional list of directories to limit the search to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#709) [Path('/root/.fastai/data/mnist_tiny/train/7/942.png'),Path('/root/.fastai/data/mnist_tiny/train/7/9162.png'),Path('/root/.fastai/data/mnist_tiny/train/7/7001.png'),Path('/root/.fastai/data/mnist_tiny/train/7/7017.png'),Path('/root/.fastai/data/mnist_tiny/train/7/9351.png'),Path('/root/.fastai/data/mnist_tiny/train/7/703.png'),Path('/root/.fastai/data/mnist_tiny/train/7/7304.png'),Path('/root/.fastai/data/mnist_tiny/train/7/8345.png'),Path('/root/.fastai/data/mnist_tiny/train/7/8559.png'),Path('/root/.fastai/data/mnist_tiny/train/7/884.png')...]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t3 = get_files(path/'train'/'3', extensions='.png', recurse=False)\n",
    "t7 = get_files(path/'train'/'7', extensions='.png', recurse=False)\n",
    "t  = get_files(path/'train', extensions='.png', recurse=True)\n",
    "test_eq(len(t), len(t3)+len(t7))\n",
    "test_eq(len(get_files(path/'train'/'3', extensions='.jpg', recurse=False)),0)\n",
    "test_eq(len(t), len(get_files(path, extensions='.png', recurse=True, folders='train')))\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "test_eq(len(get_files(path/'train'/'3', recurse=False)),346)\n",
    "test_eq(len(get_files(path, extensions='.png', recurse=True, folders=['train', 'test'])),729)\n",
    "test_eq(len(get_files(path, extensions='.png', recurse=True, folders='train')),709)\n",
    "test_eq(len(get_files(path, extensions='.png', recurse=True, folders='training')),0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's often useful to be able to create functions with customized behavior. `fastai.data` generally uses functions named as CamelCase verbs ending in `er` to create these functions. `FileGetter` is a simple example of such a function creator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def FileGetter(suf='', extensions=None, recurse=True, folders=None):\n",
    "    \"Create `get_files` partial function that searches path suffix `suf`, only in `folders`, if specified, and passes along args\"\n",
    "    def _inner(o, extensions=extensions, recurse=recurse, folders=folders):\n",
    "        return get_files(o/suf, extensions, recurse, folders)\n",
    "    return _inner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpng = FileGetter(extensions='.png', recurse=False)\n",
    "test_eq(len(t7), len(fpng(path/'train'/'7')))\n",
    "test_eq(len(t), len(fpng(path/'train', recurse=True)))\n",
    "fpng_r = FileGetter(extensions='.png', recurse=True)\n",
    "test_eq(len(t), len(fpng_r(path/'train')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "image_extensions = set(k for k,v in mimetypes.types_map.items() if v.startswith('image/'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def get_image_files(path, recurse=True, folders=None):\n",
    "    \"Get image files in `path` recursively, only in `folders`, if specified.\"\n",
    "    return get_files(path, extensions=image_extensions, recurse=recurse, folders=folders)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is simply `get_files` called with a list of standard image extensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(len(t), len(get_image_files(path, recurse=True, folders='train')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def ImageGetter(suf='', recurse=True, folders=None):\n",
    "    \"Create `get_image_files` partial function that searches path suffix `suf` and passes along `kwargs`, only in `folders`, if specified.\"\n",
    "    def _inner(o, recurse=recurse, folders=folders): return get_image_files(o/suf, recurse, folders)\n",
    "    return _inner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same as `FileGetter`, but for image extensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(len(get_files(path/'train', extensions='.png', recurse=True, folders='3')),\n",
    "        len(ImageGetter(   'train',                    recurse=True, folders='3')(path)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def get_text_files(path, recurse=True, folders=None):\n",
    "    \"Get text files in `path` recursively, only in `folders`, if specified.\"\n",
    "    return get_files(path, extensions=['.txt'], recurse=recurse, folders=folders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def ItemGetter(i):\n",
    "    \"Creates a proper transform that applies `itemgetter(i)` (even on a tuple)\"\n",
    "    return ItemTransform(itemgetter(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(ItemGetter(1)((1,2,3)),  2)\n",
    "test_eq(ItemGetter(1)(L(1,2,3)), 2)\n",
    "test_eq(ItemGetter(1)([1,2,3]),  2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next set of functions are used to *split* data into training and validation sets. The functions return two lists - a list of indices or masks for each of training and validation sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def RandomSplitter(valid_pct=0.2, seed=None, **kwargs):\n",
    "    \"Create function that splits `items` between train/val with `valid_pct` randomly.\"\n",
    "    def _inner(o, **kwargs):\n",
    "        if seed is not None: torch.manual_seed(seed)\n",
    "        rand_idx = L(int(i) for i in torch.randperm(len(o)))\n",
    "        cut = int(valid_pct * len(o))\n",
    "        return rand_idx[cut:],rand_idx[:cut]\n",
    "    return _inner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src = list(range(30))\n",
    "f = RandomSplitter(seed=42)\n",
    "trn,val = f(src)\n",
    "assert 0<len(trn)<len(src)\n",
    "assert all(o not in val for o in trn)\n",
    "test_eq(len(trn), len(src)-len(val))\n",
    "# test random seed consistency\n",
    "test_eq(f(src)[0], trn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use scikit-learn train_test_split. This allow to *split* items in a stratified fashion (uniformely according to the ‘labels‘ distribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def TrainTestSplitter(test_size=0.2, random_state=None, stratify=None, **kwargs):\n",
    "    \"Split ‘items‘ into random train and test subsets using sklearn train_test_split utility.\"\n",
    "    def _inner(o, **kwargs):\n",
    "        train, valid = train_test_split(range(len(o)), test_size=test_size, random_state=random_state, stratify=stratify, **kwargs)\n",
    "        return L(train), L(valid)\n",
    "    return _inner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src = list(range(30))\n",
    "labels = [0] * 20 + [1] * 10\n",
    "test_size = 0.2\n",
    "\n",
    "f = TrainTestSplitter(test_size=test_size, random_state=42, stratify=labels)\n",
    "trn,val = f(src)\n",
    "assert 0<len(trn)<len(src)\n",
    "assert all(o not in val for o in trn)\n",
    "test_eq(len(trn), len(src)-len(val))\n",
    "\n",
    "# test random seed consistency\n",
    "test_eq(f(src)[0], trn)\n",
    "\n",
    "# test labels distribution consistency\n",
    "# there should be test_size % of zeroes and ones respectively in the validation set\n",
    "test_eq(len([t for t in val if t < 20]) / 20, test_size)\n",
    "test_eq(len([t for t in val if t > 20]) / 10, test_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def IndexSplitter(valid_idx):\n",
    "    \"Split `items` so that `val_idx` are in the validation set and the others in the training set\"\n",
    "    def _inner(o, **kwargs):\n",
    "        train_idx = np.setdiff1d(np.array(range_of(o)), np.array(valid_idx))\n",
    "        return L(train_idx, use_list=True), L(valid_idx, use_list=True)\n",
    "    return _inner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "items = list(range(10))\n",
    "splitter = IndexSplitter([3,7,9])\n",
    "test_eq(splitter(items),[[0,1,2,4,5,6,8],[3,7,9]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def _grandparent_idxs(items, name): return mask2idxs(Path(o).parent.parent.name == name for o in items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def GrandparentSplitter(train_name='train', valid_name='valid'):\n",
    "    \"Split `items` from the grand parent folder names (`train_name` and `valid_name`).\"\n",
    "    def _inner(o, **kwargs):\n",
    "        return _grandparent_idxs(o, train_name),_grandparent_idxs(o, valid_name)\n",
    "    return _inner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fnames = [path/'train/3/9932.png', path/'valid/7/7189.png', \n",
    "          path/'valid/7/7320.png', path/'train/7/9833.png',  \n",
    "          path/'train/3/7666.png', path/'valid/3/925.png',\n",
    "          path/'train/7/724.png', path/'valid/3/93055.png']\n",
    "splitter = GrandparentSplitter()\n",
    "test_eq(splitter(fnames),[[0,3,4,6],[1,2,5,7]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def FuncSplitter(func):\n",
    "    \"Split `items` by result of `func` (`True` for validation, `False` for training set).\"\n",
    "    def _inner(o, **kwargs):\n",
    "        val_idx = mask2idxs(func(o_) for o_ in o)\n",
    "        return IndexSplitter(val_idx)(o)\n",
    "    return _inner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "splitter = FuncSplitter(lambda o: Path(o).parent.parent.name == 'valid')\n",
    "test_eq(splitter(fnames),[[0,3,4,6],[1,2,5,7]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def MaskSplitter(mask):\n",
    "    \"Split `items` depending on the value of `mask`.\"\n",
    "    def _inner(o, **kwargs): return IndexSplitter(mask2idxs(mask))(o)\n",
    "    return _inner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "items = list(range(6))\n",
    "splitter = MaskSplitter([True,False,False,True,False,True])\n",
    "test_eq(splitter(items),[[1,2,4],[0,3,5]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def FileSplitter(fname):\n",
    "    \"Split `items` depending on the value of `mask`.\"\n",
    "    valid = Path(fname).read().split('\\n')\n",
    "    def _func(x): return x.name in valid\n",
    "    def _inner(o, **kwargs): return FuncSplitter(_func)(o)\n",
    "    return _inner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tempfile.TemporaryDirectory() as d:\n",
    "    fname = Path(d)/'valid.txt'\n",
    "    fname.write('\\n'.join([Path(fnames[i]).name for i in [1,3,4]]))\n",
    "    splitter = FileSplitter(fname)\n",
    "    test_eq(splitter(fnames),[[0,2,5,6,7],[1,3,4]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def ColSplitter(col='is_valid'):\n",
    "    \"Split `items` (supposed to be a dataframe) by value in `col`\"\n",
    "    def _inner(o, **kwargs):\n",
    "        assert isinstance(o, pd.DataFrame), \"ColSplitter only works when your items are a pandas DataFrame\"\n",
    "        valid_idx = o[col].values\n",
    "        return IndexSplitter(mask2idxs(valid_idx))(o)\n",
    "    return _inner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'a': [0,1,2,3,4], 'b': [True,False,True,True,False]})\n",
    "splits = ColSplitter('b')(df)\n",
    "test_eq(splits, [[1,4], [0,2,3]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final set of functions is used to *label* a single item of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def parent_label(o, **kwargs):\n",
    "    \"Label `item` with the parent folder name.\"\n",
    "    return Path(o).parent.name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that `parent_label` doesn't have anything customize, so it doesn't return a function - you can just use it directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['3', '7', '7', '7', '3', '3', '7', '3']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_eq(parent_label(fnames[0]), '3')\n",
    "test_eq(parent_label(\"fastai_dev/dev/data/mnist_tiny/train/3/9932.png\"), '3')\n",
    "[parent_label(o) for o in fnames]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "#test for MS Windows when os.path.sep is '\\\\' instead of '/'\n",
    "test_eq(parent_label(os.path.join(\"fastai_dev\",\"dev\",\"data\",\"mnist_tiny\",\"train\", \"3\", \"9932.png\") ), '3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class RegexLabeller():\n",
    "    \"Label `item` with regex `pat`.\"\n",
    "    def __init__(self, pat, match=False):\n",
    "        self.pat = re.compile(pat)\n",
    "        self.matcher = self.pat.match if match else self.pat.search\n",
    "\n",
    "    def __call__(self, o, **kwargs):\n",
    "        res = self.matcher(str(o))\n",
    "        assert res,f'Failed to find \"{self.pat}\" in \"{o}\"'\n",
    "        return res.group(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`RegexLabeller` is a very flexible function since it handles any regex search of the stringified item. Pass `match=True` to use `re.match` (i.e. check only start of string), or `re.search` otherwise (default).\n",
    "\n",
    "For instance, here's an example the replicates the previous `parent_label` results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['3', '7', '7', '7', '3', '3', '7', '3']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = RegexLabeller(fr'{os.path.sep}(\\d){os.path.sep}')\n",
    "test_eq(f(fnames[0]), '3')\n",
    "[f(o) for o in fnames]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = RegexLabeller(r'(\\d*)', match=True)\n",
    "test_eq(f(fnames[0].name), '9932')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class ColReader():\n",
    "    \"Read `cols` in `row` with potential `pref` and `suff`\"\n",
    "    def __init__(self, cols, pref='', suff='', label_delim=None):\n",
    "        store_attr(self, 'suff,label_delim')\n",
    "        self.pref = str(pref) + os.path.sep if isinstance(pref, Path) else pref\n",
    "        self.cols = L(cols)\n",
    "\n",
    "    def _do_one(self, r, c):\n",
    "        o = r[c] if isinstance(c, int) else getattr(r, c)\n",
    "        if len(self.pref)==0 and len(self.suff)==0 and self.label_delim is None: return o\n",
    "        if self.label_delim is None: return f'{self.pref}{o}{self.suff}'\n",
    "        else: return o.split(self.label_delim) if len(o)>0 else []\n",
    "\n",
    "    def __call__(self, o, **kwargs): return detuplify(tuple(self._do_one(o, c) for c in self.cols))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`cols` can be a list of column names or a list of indices (or a mix of both). If `label_delim` is passed, the result is split using it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'a': 'a b c d'.split(), 'b': ['1 2', '0', '', '1 2 3']})\n",
    "f = ColReader('a', pref='0', suff='1')\n",
    "test_eq([f(o) for o in df.itertuples()], '0a1 0b1 0c1 0d1'.split())\n",
    "\n",
    "f = ColReader('b', label_delim=' ')\n",
    "test_eq([f(o) for o in df.itertuples()], [['1', '2'], ['0'], [], ['1', '2', '3']])\n",
    "\n",
    "df['a1'] = df['a']\n",
    "f = ColReader(['a', 'a1'], pref='0', suff='1')\n",
    "test_eq([f(o) for o in df.itertuples()], [('0a1', '0a1'), ('0b1', '0b1'), ('0c1', '0c1'), ('0d1', '0d1')])\n",
    "\n",
    "df = pd.DataFrame({'a': [L(0,1), L(2,3,4), L(5,6,7)]})\n",
    "f = ColReader('a')\n",
    "test_eq([f(o) for o in df.itertuples()], [L(0,1), L(2,3,4), L(5,6,7)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Categorize -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class CategoryMap(CollBase):\n",
    "    \"Collection of categories with the reverse mapping in `o2i`\"\n",
    "    def __init__(self, col, sort=True, add_na=False):\n",
    "        if is_categorical_dtype(col): items = L(col.cat.categories, use_list=True)\n",
    "        else:\n",
    "            if not hasattr(col,'unique'): col = L(col, use_list=True)\n",
    "            # `o==o` is the generalized definition of non-NaN used by Pandas\n",
    "            items = L(o for o in col.unique() if o==o)\n",
    "            if sort: items = items.sorted()\n",
    "        self.items = '#na#' + items if add_na else items\n",
    "        self.o2i = defaultdict(int, self.items.val2idx()) if add_na else dict(self.items.val2idx())\n",
    "    def __eq__(self,b): return all_equal(b,self)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = CategoryMap([4,2,3,4])\n",
    "test_eq(t, [2,3,4])\n",
    "test_eq(t.o2i, {2:0,3:1,4:2})\n",
    "test_fail(lambda: t.o2i['unseen label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = CategoryMap([4,2,3,4], add_na=True)\n",
    "test_eq(t, ['#na#',2,3,4])\n",
    "test_eq(t.o2i, {'#na#':0,2:1,3:2,4:3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = CategoryMap(pd.Series([4,2,3,4]), sort=False)\n",
    "test_eq(t, [4,2,3])\n",
    "test_eq(t.o2i, {4:0,2:1,3:2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = pd.Series(pd.Categorical(['M','H','L','M'], categories=['H','M','L'], ordered=True))\n",
    "t = CategoryMap(col)\n",
    "test_eq(t, ['H','M','L'])\n",
    "test_eq(t.o2i, {'H':0,'M':1,'L':2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class Categorize(Transform):\n",
    "    \"Reversible transform of category string to `vocab` id\"\n",
    "    loss_func,order=CrossEntropyLossFlat(),1\n",
    "    def __init__(self, vocab=None, add_na=False):\n",
    "        self.add_na = add_na\n",
    "        self.vocab = None if vocab is None else CategoryMap(vocab, add_na=add_na)\n",
    "\n",
    "    def setups(self, dsets):\n",
    "        if self.vocab is None and dsets is not None: self.vocab = CategoryMap(dsets, add_na=self.add_na)\n",
    "        self.c = len(self.vocab)\n",
    "\n",
    "    def encodes(self, o): return TensorCategory(self.vocab.o2i[o])\n",
    "    def decodes(self, o): return Category      (self.vocab    [o])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class Category(str, ShowTitle): _show_args = {'label': 'category'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat = Categorize()\n",
    "tds = Datasets(['cat', 'dog', 'cat'], tfms=[cat])\n",
    "test_eq(cat.vocab, ['cat', 'dog'])\n",
    "test_eq(cat('cat'), 0)\n",
    "test_eq(cat.decode(1), 'dog')\n",
    "test_stdout(lambda: show_at(tds,2), 'cat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat = Categorize(add_na=True)\n",
    "tds = Datasets(['cat', 'dog', 'cat'], tfms=[cat])\n",
    "test_eq(cat.vocab, ['#na#', 'cat', 'dog'])\n",
    "test_eq(cat('cat'), 1)\n",
    "test_eq(cat.decode(2), 'dog')\n",
    "test_stdout(lambda: show_at(tds,2), 'cat')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multicategorize -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class MultiCategorize(Categorize):\n",
    "    \"Reversible transform of multi-category strings to `vocab` id\"\n",
    "    loss_func,order=BCEWithLogitsLossFlat(),1\n",
    "    def __init__(self, vocab=None, add_na=False):\n",
    "        self.add_na = add_na\n",
    "        self.vocab = None if vocab is None else CategoryMap(vocab, add_na=add_na)\n",
    "\n",
    "    def setups(self, dsets):\n",
    "        if not dsets: return\n",
    "        if self.vocab is None:\n",
    "            vals = set()\n",
    "            for b in dsets: vals = vals.union(set(b))\n",
    "            self.vocab = CategoryMap(list(vals), add_na=self.add_na)\n",
    "\n",
    "    def encodes(self, o): return TensorMultiCategory([self.vocab.o2i[o_] for o_ in o])\n",
    "    def decodes(self, o): return MultiCategory      ([self.vocab    [o_] for o_ in o])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class MultiCategory(L):\n",
    "    def show(self, ctx=None, sep=';', color='black', **kwargs):\n",
    "        return show_title(sep.join(self.map(str)), ctx=ctx, color=color, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat = MultiCategorize()\n",
    "tds = Datasets([['b', 'c'], ['a'], ['a', 'c'], []], tfms=[cat])\n",
    "test_eq(tds[3][0], tensor([]))\n",
    "test_eq(cat.vocab, ['a', 'b', 'c'])\n",
    "test_eq(cat(['a', 'c']), tensor([0,2]))\n",
    "test_eq(cat([]), tensor([]))\n",
    "test_eq(cat.decode([1]), ['b'])\n",
    "test_eq(cat.decode([0,2]), ['a', 'c'])\n",
    "test_stdout(lambda: show_at(tds,2), 'a;c')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class OneHotEncode(Transform):\n",
    "    \"One-hot encodes targets\"\n",
    "    order=2\n",
    "    def __init__(self, c=None): self.c = c\n",
    "\n",
    "    def setups(self, dsets):\n",
    "        if self.c is None: self.c = len(L(getattr(dsets, 'vocab', None)))\n",
    "        if not self.c: warn(\"Couldn't infer the number of classes, please pass a value for `c` at init\")\n",
    "\n",
    "    def encodes(self, o): return TensorMultiCategory(one_hot(o, self.c).float())\n",
    "    def decodes(self, o): return one_hot_decode(o, None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Works in conjunction with ` MultiCategorize` or on its own if you have one-hot encoded targets (pass a `vocab` for decoding and `do_encode=False` in this case)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_tfm = OneHotEncode(c=3)\n",
    "test_eq(_tfm([0,2]), tensor([1.,0,1]))\n",
    "test_eq(_tfm.decode(tensor([0,1,1])), [1,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tds = Datasets([['b', 'c'], ['a'], ['a', 'c'], []], [[MultiCategorize(), OneHotEncode()]])\n",
    "test_eq(tds[1], [tensor([1.,0,0])])\n",
    "test_eq(tds[3], [tensor([0.,0,0])])\n",
    "test_eq(tds.decode([tensor([False, True, True])]), [['b','c']])\n",
    "test_eq(type(tds[1][0]), TensorMultiCategory)\n",
    "test_stdout(lambda: show_at(tds,2), 'a;c')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "#test with passing the vocab\n",
    "tds = Datasets([['b', 'c'], ['a'], ['a', 'c'], []], [[MultiCategorize(vocab=['a', 'b', 'c']), OneHotEncode()]])\n",
    "test_eq(tds[1], [tensor([1.,0,0])])\n",
    "test_eq(tds[3], [tensor([0.,0,0])])\n",
    "test_eq(tds.decode([tensor([False, True, True])]), [['b','c']])\n",
    "test_eq(type(tds[1][0]), TensorMultiCategory)\n",
    "test_stdout(lambda: show_at(tds,2), 'a;c')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class EncodedMultiCategorize(Categorize):\n",
    "    \"Transform of one-hot encoded multi-category that decodes with `vocab`\"\n",
    "    loss_func,order=BCEWithLogitsLossFlat(),1\n",
    "    def __init__(self, vocab): self.vocab,self.c = vocab,len(vocab)\n",
    "    def encodes(self, o): return TensorCategory(tensor(o).float())\n",
    "    def decodes(self, o): return MultiCategory (one_hot_decode(o, self.vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_tfm = EncodedMultiCategorize(vocab=['a', 'b', 'c'])\n",
    "test_eq(_tfm([1,0,1]), tensor([1., 0., 1.]))\n",
    "test_eq(type(_tfm([1,0,1])), TensorCategory)\n",
    "test_eq(_tfm.decode(tensor([False, True, True])), ['b','c'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class RegressionSetup(Transform):\n",
    "    \"Transform that floatifies targets\"\n",
    "    def __init__(self, c=None): self.c = c\n",
    "    def encodes(self, o): return tensor(o).float()\n",
    "    def setups(self, dsets):\n",
    "        if self.c is not None: return\n",
    "        try: self.c = len(dsets[0]) if hasattr(dsets[0], '__len__') else 1\n",
    "        except: self.c = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_tfm = RegressionSetup()\n",
    "dsets = Datasets([0, 1, 2], RegressionSetup)\n",
    "test_eq(dsets.c, 1)\n",
    "test_eq_type(dsets[0], (tensor(0.),))\n",
    "\n",
    "dsets = Datasets([[0, 1, 2], [3,4,5]], RegressionSetup)\n",
    "test_eq(dsets.c, 3)\n",
    "test_eq_type(dsets[0], (tensor([0.,1.,2.]),))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def get_c(dls):\n",
    "    if getattr(dls, 'c', False): return dls.c\n",
    "    if getattr(getattr(dls.train, 'after_item', None), 'c', False): return dls.train.after_item.c\n",
    "    if getattr(getattr(dls.train, 'after_batch', None), 'c', False): return dls.train.after_batch.c\n",
    "    vocab = getattr(dls, 'vocab', [])\n",
    "    if len(vocab) > 0 and is_listy(vocab[-1]): vocab = vocab[-1]\n",
    "    return len(vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## End-to-end dataset example with MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's show how to use those functions to grab the mnist dataset in a `Datasets`. First we grab all the images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = untar_data(URLs.MNIST_TINY)\n",
    "items = get_image_files(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we split between train and validation depending on the folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((#3) [Path('/root/.fastai/data/mnist_tiny/train/7/942.png'),Path('/root/.fastai/data/mnist_tiny/train/7/9162.png'),Path('/root/.fastai/data/mnist_tiny/train/7/7001.png')],\n",
       " (#3) [Path('/root/.fastai/data/mnist_tiny/valid/7/9566.png'),Path('/root/.fastai/data/mnist_tiny/valid/7/8654.png'),Path('/root/.fastai/data/mnist_tiny/valid/7/703.png')])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "splitter = GrandparentSplitter()\n",
    "splits = splitter(items)\n",
    "train,valid = (items[i] for i in splits)\n",
    "train[:3],valid[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our inputs are images that we open and convert to tensors, our targets are labeled depending on the parent directory and are categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "def open_img(fn:Path): return Image.open(fn).copy()\n",
    "def img2tensor(im:Image.Image): return TensorImage(array(im)[None])\n",
    "\n",
    "tfms = [[open_img, img2tensor],\n",
    "        [parent_label, Categorize()]]\n",
    "train_ds = Datasets(train, tfms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y = train_ds[3]\n",
    "xd,yd = decode_at(train_ds,3)\n",
    "test_eq(parent_label(train[3]),yd)\n",
    "test_eq(array(Image.open(train[3])),xd[0].numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAEQAAABUCAYAAAA7xZEpAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAADuElEQVR4nO2bTyhtWxzHP4vXEW4xvCm9konEiNKjlGIoETK4biZkaiIlZCizNzS6byRHb6bI33pvwEBiwMxNDF4GCOXfufYdsO3r51xnP8c+a3X7ferUOWvvWt++fc9v/dba5xjP81ACsmwLcA01RKCGCNQQgRoiUEMEaojAuiHGmEvx+maM+dOWnt9sTezjed4H/70x5gPwHxC3pcd6QgRtwDHwjy0BrhnyGfjLs7ifMK7sZYwxvwP7QKnneV9t6XApIZ+Af22aAW4Z0g18sS3Cia+MMeYPYBH46HnehU0triTkM/C3bTPAkYS4hCsJcQY1RKCGCNQQQarN3a9ccU2yQU2IQA0RqCECNUSghgjUEIEaIlBDBGqIQA0RqCECNUSghggy8ijz5uYGgOnpaQB6enpe3JOXlwfAyMgIAB0dHQAUFxcDkJ2dHblO0IS8INUhc1rnIcvLywAMDg4CsLW19fOJHnUY8/yYYmJiAoCuri4AioqK0pH0I3oeEoZIEjI/Pw9Aa2srAFdXVwBkZf3c//v7+5T3ALS3twMwOjoKQFlZ2VskgiYkHJGsMnNzc0Cwusi64NPd3Q3AwcEBGxsbACwsLACwvb0NwNjYGAAnJycAzMzMANDf3w+klZCkaEIEkdSQw8NDAMrLywFobGwEoKWlBQhqS25uLgCJRIJEIgEE/YhPbW0tAOvr6w+CHvWurq4CUF9f/xaJoDUkHJHUEL+7PD8/D3V/LBYjFos9Gzs6OgJgf38fCJLhk5OTk67MpGhCBNZ/lim5u7sDoLe3F4Dj42MgWKmqq6sBqKmpiWR+Zwzxi+rw8DAQLL8Sv+mLCv3KCJxJyPX1NQCTk5NJrw8MDABQWFgYqQ5NiCDS7f//4fLyEoCCgoJn41VVVQCsrKwAkJ+f/15TamMWBidqyO3tLc3NzcDLBmx8fBx412S8iiZE4ERC4vE4a2trQNCAtbW1AWlt3t6EJkTgxCrT1NTE0tLSg6DHhOzs7ADBEUIE6CoTBqs15PT0FIDNzc2nscrKSgBKS0utaNKECKwk5OzsDIC6urqnz36fEY8//CEzqgOgVGhCBBlNyMXFw/+DhoaGANjb23u65j+itFU7fDQhgoz2Ibu7uwBUVFS8uLa4uAhAQ0PDe075GtqHhCGjNWRqairpeF9fXyaT8SqaEIEThpSUlNiW8IQThrhERleZ2dlZADo7O4Hn56WZOhH7AV1lwuDEeYglNCFhSNWHJP8t1C+MJkSghgjUEIEaIlBDBGqI4DtvBwT8Vtb0wwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 72x72 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax = show_at(train_ds, 3, cmap=\"Greys\", figsize=(1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert ax.title.get_text() in ('3','7')\n",
    "test_fig_exists(ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ToTensor -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class ToTensor(Transform):\n",
    "    \"Convert item to appropriate tensor class\"\n",
    "    order = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IntToFloatTensor -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class IntToFloatTensor(Transform):\n",
    "    \"Transform image to float tensor, optionally dividing by 255 (e.g. for images).\"\n",
    "    order = 10 #Need to run after PIL transforms on the GPU\n",
    "    def __init__(self, div=255., div_mask=1): store_attr(self, 'div,div_mask')\n",
    "    def encodes(self, o:TensorImage): return o.float().div_(self.div)\n",
    "    def encodes(self, o:TensorMask ): return o.div_(self.div_mask).long()\n",
    "    def decodes(self, o:TensorImage): return ((o.clamp(0., 1.) * self.div).long()) if self.div else o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = (TensorImage(tensor(1)),tensor(2).long(),TensorMask(tensor(3)))\n",
    "tfm = IntToFloatTensor()\n",
    "ft = tfm(t)\n",
    "test_eq(ft, [1./255, 2, 3])\n",
    "test_eq(type(ft[0]), TensorImage)\n",
    "test_eq(type(ft[2]), TensorMask)\n",
    "test_eq(ft[0].type(),'torch.FloatTensor')\n",
    "test_eq(ft[1].type(),'torch.LongTensor')\n",
    "test_eq(ft[2].type(),'torch.LongTensor')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalization -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def broadcast_vec(dim, ndim, *t, cuda=True):\n",
    "    \"Make a vector broadcastable over `dim` (out of `ndim` total) by prepending and appending unit axes\"\n",
    "    v = [1]*ndim\n",
    "    v[dim] = -1\n",
    "    f = to_device if cuda else noop\n",
    "    return [f(tensor(o).view(*v)) for o in t]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "@docs\n",
    "class Normalize(Transform):\n",
    "    \"Normalize/denorm batch of `TensorImage`\"\n",
    "    order=99\n",
    "    def __init__(self, mean=None, std=None, axes=(0,2,3)): self.mean,self.std,self.axes = mean,std,axes\n",
    "\n",
    "    @classmethod\n",
    "    def from_stats(cls, mean, std, dim=1, ndim=4, cuda=True): return cls(*broadcast_vec(dim, ndim, mean, std, cuda=cuda))\n",
    "\n",
    "    def setups(self, dl:DataLoader):\n",
    "        if self.mean is None or self.std is None:\n",
    "            x,*_ = dl.one_batch()\n",
    "            self.mean,self.std = x.mean(self.axes, keepdim=True),x.std(self.axes, keepdim=True)+1e-7\n",
    "\n",
    "    def encodes(self, x:TensorImage): return (x-self.mean) / self.std\n",
    "    def decodes(self, x:TensorImage):\n",
    "        f = to_cpu if x.device.type=='cpu' else noop\n",
    "        return (x*f(self.std) + f(self.mean))\n",
    "\n",
    "    _docs=dict(encodes=\"Normalize batch\", decodes=\"Denormalize batch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean,std = [0.5]*3,[0.5]*3\n",
    "mean,std = broadcast_vec(1, 4, mean, std)\n",
    "batch_tfms = [IntToFloatTensor, Normalize.from_stats(mean,std)]\n",
    "tdl = TfmdDL(train_ds, after_batch=batch_tfms, bs=4, device=default_device())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y  = tdl.one_batch()\n",
    "xd,yd = tdl.decode((x,y))\n",
    "\n",
    "test_eq(x.type(), 'torch.cuda.FloatTensor' if default_device().type=='cuda' else 'torch.FloatTensor')\n",
    "test_eq(xd.type(), 'torch.LongTensor')\n",
    "test_eq(type(x), TensorImage)\n",
    "test_eq(type(y), TensorCategory)\n",
    "assert x.mean()<0.0\n",
    "assert x.std()>0.5\n",
    "assert 0<xd.float().mean()/255.<1\n",
    "assert 0<xd.float().std()/255.<0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "nrm = Normalize()\n",
    "batch_tfms = [IntToFloatTensor(), nrm]\n",
    "tdl = TfmdDL(train_ds, after_batch=batch_tfms, bs=4)\n",
    "x,y  = tdl.one_batch()\n",
    "test_close(x.mean(), 0.0, 1e-4)\n",
    "assert x.std()>0.9, x.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Just for visuals\n",
    "from fastai2.vision.core import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAEQAAABUCAYAAAA7xZEpAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAEB0lEQVR4nO2bbYhUVRjHf2dm1ppQSUy03KwP20gYmKkhFiVpfkiCQFTEzMAMzUqISr/ot2CTfKkFDVKpCJYwhFUESxRlt+wF3WZRDBIFI10r2kxlmdaZ24czN73P7qwzO3PnHOL5wbCXs/fl2f/+5t5z7rnXBEGAcoOE6wJ8QwMRaCACDUSggQg0EIEGInAeiDHmqvjkjTEtrupJuTpwSBAEw8NlY8xwoBvY7aoe54YI5gO/Ae2uCvAtkGXAp4HD8YTxZSxjjLkPOAs0BUFwzlUdPhmyFOhwGQb4FcgLwCeui/DiK2OMmQkcBMYFQXDFZS2+GLIM2OM6DPDEEJ/wxRBv0EAEGohAAxEMOrh7OrHgf3vGPVjYbQZqV0MEGohAAxFoIAINRKCBCDQQgQYi0EAEGohAAxFoIAINRKCBCDQQQSyT3anG8QBcntE46HobmncBMDudI2ns/yYfFAbd5rHsQnuMXaMj7SN+/huAQvZ05QXfhBoiqKkhv66bCUD68T8A+GbKtrK2KwCFIF/Wuu2TP7cL70fbJ36xGoAH1pS1m5KoIYKqDLk+eyoAk97tAmDbmI0ATEilqyyrclrmfQzA5rYlAKQOHx/SftQQQVWG5EbZzTfd/W2xpf5mhMxNXwOg+U5b01D/MDVE4Pyhu5CpPzwPQOvDtm+SaRjmpA41RFCVIYk+O7HX+Y/tXf6Zt09YbnpxccX7uvfMRQDemPAyAIVhycjvP/jM9mmaGm4bcPsHjy4HIHP4JwDK69X0p6pA0m3fA7C+bXqkPcGPFe/rerjQfam4jyi5IMlgFH6/HYD8X5crPvbN6FdG4M1JtRQX3rbDgbHJjmJLtOTWK2MBuH9fX02Op4YIvDPEFC+3v7w5DYC9K+1w4K5ktNN3PGd/ti6cA0BD19C66hI1ROCdIefXWjOyq8I3RKJmbO3JAPDVqicASHR11vT4aojAG0PCq8n+FRuLLVEz9l4bBcCBNbMASLXX5pwhUUMETg0Jryjn1077z4zGEjeXPlr0LACpznjMCFFDBE4M6X3uUQC6Z9jxyamlLZS6mnzYaa8mE8+dBYY+aCsXNURQV0Nyz9hR8UvNewBYPOJSv3UO9d4BwJevPglA05ETQPxmhKghgroY0jfHTlfs3L4FGHiaIuxn7FgwD4Bk9kQ9SuuHGiKoiyFPbf4aKD2BtbUnc6MHmo23n3Er1BBBrIZceMuOT+aPfK/YEr1B/MiW1wAY911vbGOTSlFDBLEacjVj73OGUwfhdMUr77wOwD07j9kVPXozVA0RxGKImTIJgLmTT0baV5+yjyqM3nEsjsPWBDVEEIshPQ+NBGDf+I5brOkfaohA3/0XqCECDUSggQg0EIEGItBABP8CNRjjpfKXKy4AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 72x72 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAEQAAABUCAYAAAA7xZEpAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAD8ElEQVR4nO2bb2hVZRzHP8+9bmMirD9jOEy0WrveGDSZ+WfQIiV8E4GYQvgP0kQYoXuxIF/4JsRXE7GyV1GrQGEwrKgYBiUWbaUEMvQ2m/Zi6TSWbq5w7N4dXzz3NPfb3XZH99znIX4fGLucc+49P77nc55znuc8xwRBgDJJzHUBvqGBCDQQgQYi0EAEGohAAxE4D8QYMyr+MsaYd1zVs8DVjkOCIFgUfjbGLAIGgQ5X9Tg3RLAZuAWcc1WAb4HsAj4OHPYnjC99GWPMMuAqUBMEwTVXdfhkyA7ge5dhgF+B7ATaXRfhxSljjGkEzgCLgyC467IWXwzZBXS6DgM8McQnfDHEGzQQgQYi0EAEs3buXoxt+d+2uGcmOkyu5WqIQAMRaCACDUSggQg0EIEGItBABBqIQAMRaCCCgj6oevSHhwFoX/4NAKvPbwNgeHjh3F++UwJAzcl7OVfHf/kVgIl7udcXCjVEUFBDHin9B4AJJgDoXvUJALFs7uHyXPy7zebc2xwcXAPA6XNrAVjalQGg7Ouf/2vZog5lCrMOMs93PCT+UAUA/a1PA3B6WxsAY0EcgGTpzPnnY9GD2x27XQvAdxsTAKT/uD6fUnU8JF8Kaogk9kzS7mTgJgC3NiXm/M7Ik/b/qqYUAPuqvwVgTdm4/U1hUsv15wDof3Z+Vx81JE8iNaQQxGutMjdfqAKg+9C7wKQhPWP2/uXwE/Xz+l01JE+cT6mai0xfPwAje6whJcZescaz7r6ZegWACn4ryP7UEIH3hixYthSAtk126sh4YO9QwzZk7Muq7JZqSCR4a0g8UQPAka5PAUiUxLNr7DFcd2E7AFUnfizofr0LJDxF6k7ZU2AyCEtrtpNX3fw3AOkCz2/RU0bgnSGpA0sA6KzqnLK8bagOgCsvVQKQvjEQyf7VEIE3hvz5ue34pRreyy6ZeqzO7rVtBzcuRlqHGiLwwpDf315Hb8PUTttfmTEAGrtaAEim+gDIRFyLGiJwYkg41HjlxOMAnG86CpQCk2a8fPE1AGpft4PIUZsRooYIimpIeBfa1/wYAL3PH59WRthmhGYUGzVEUFRDwrvQS1uPT1u3odcO9CRbi3M1mQk1RFAUQwbeagQgtTV8+3T6cRg6Ww1A+R2nL1SpIZJIDYnV20eabbs/AGZ+TLnii2aSHYOAu7YjRA0RRGrIyg97AdhQHk6TsGSyo1x1n70BQGL/BTLpdJSl5I0aIojUkMqS0ZzLQzOeau4BwPnz0gdQQwSRGvL+VxsBWL/lMgCvfpTtpxz+CfDLjBA1ROD9dIio0OkQeaKBCDQQgb77L1BDBBqIQAMRaCACDUSggQjuAw4lDhNy1o1cAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 72x72 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAEQAAABUCAYAAAA7xZEpAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAEYklEQVR4nO2be2hbVRzHPyfd+sBiKavrcKkdshVf4GTqasYUXxMfOHC0fzjsxOdEEGRD/WPI/hGEUS06RdiDbv7jNhGsE9mmIti5RxTcqrJVbH1A0a4umzZbg8u9/nGShvzaZCHc5lzl94Fym3NzOD++95OTc08S4/s+So6I6wLChgYi0EAEGohAAxFoIAINROA8EGPMuPhLG2PedFXPLFcDZ/F9vz77vzGmHvgd2OOqHueGCFYBo8CXrgoIWyBrgJ2+w/sJE5Z7GWNMKzAELPR9f9hVHWEy5BGg32UYEK5AuoAdrosIxUvGGBMDDgDzfN//22UtYTFkDfCB6zAgJIaEibAYEho0EIEGItBABEVv7u6OdPxvZ9wD3h4zXbsaItBABBqIQAMRaCACDUSggQg0EIEGItBABBqIQAMRaCCCQD7KPLu6HYBTN9rHzYftseHDbwHwJiaCGKYiqCGCQAwZbbfbJicfehuASKfdati2MQrAq/sfBKD6jM0/Ne8f29HPbUlcvmAMgCVNvwEw+NdcAEb2tgLQHD9vCz5rj97xE0GUPgU1RFD0Y4iL7ZidfuwWAPo2bgKgqaoOgAj2yntM373Y+Yv1/fWCNeT+I88AsGBTpt/wCADpsT+LlTyJ7piVSFlzyMQDNwPw6Pq9QM6MQvQk2gDoPWnfjczRBgAahr2CfU4tthcwXWdNuSM2AMA7UfvVkYFlvfaJy+xh8eEuAKKrSjOkEGqIoCxDrnrZXq21Db9kWuzV/Ox8DQDPH+sE4IqunwHwkkkAonxf8hj1u/Mfx5+LAVD10kHb4Ofb9fr1tkM315Y8xnSoIYKyDNn/nb0K3vx+APqSjQBsWb0SgGjcGlR4hiidWa0tAJyLjQOQzpiRfRc6mrJ29rTfmumhc0iglGXI1et+AuC+7Y8DUD1yBgB/aCCgsnIMPmtXuz8s35xpsUaMeykAnty2HoCWsa8CGa+sQNKJBACRfnu8EEgp+Yx3LAWgr7M701KTd/6N0/ZOsuWVYILIoi8ZgfNvMhdi5C47ebbNrp32/Bcv2hVZNfFAx1VDBKEzpKrRvoVvvvNdYOpNXtvHa+1x39czMr4aIgidIT++ZTeEVtR9mtf+R9re9l/5Xma5N0PfnlRDBKExZOQFe/N24ja7AJPL/nviTwMQ/fybGa1DDRGEwpBIbS0rH87/zVB2KzHh2bmj7pNLK1NLRUb5DxEKQ4Z3LqLvst7Mo/xN5qXvrwNg4dZDFalFDRE4NcTMrgbgqWsOTjl3+0AHAG0bgttsKgU1RODUkMGt1wHwUeOWKedSu5sBuCQ5VNGa1BCBU0N6l28HcmsOgNcSiwBo2nUcqNzckUUNETg1xPPt9fBIT7bt6lkBwJxkZdYdEjVE4MSQ1L03AXBDTdaCajaMLgFgToVWpIVQQwRODDk31w4bO/LEZNv8bttmOOaipEnUEIETQxp3HMocXYxeHDVEoL/9F6ghAg1EoIEINBCBBiLQQAT/AqA6F95WBVPnAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 72x72 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAEQAAABUCAYAAAA7xZEpAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAEA0lEQVR4nO2bb2hVZRzHP8+93hxsY7vclGWgy66aCg41CpaERJJZSBHhVNZ8sRcKRYiut76Kgr2ZSIYhTiWCNBRMEVrpi8XMoBT/jSLnYLYuE5tXRcV1d3rx3KPtt7sluHOeR/l9YJzD2bPz/Pjez55znueca4IgQLlPwnUBvqGBCDQQgQYi0EAEGohAAxE4D8QYc1P8FIwx21zVM8lVxyFBEFSE+8aYCiAH7HdVj3NDBO8AA0CnqwJ8C6QJ2Bs4nE8YX+YyxpgZQA+QDYLgkqs6fDKkEfjRZRjgVyDvAXtcF+HFv4wxph7oAGqCILjhshZfDGkCDrgOAzwxxCd8McQbNBCBBiLQQATjTu6WJd59bEfcjuH9ptRxNUSggQg0EIEGItBABBqIQAMRaCACDUSggQg0EIEGItBABLE8ykym0wD80fIcAN1Nn41qM1C4BUD90Y0A1B6wE+3Jx84AEAzdjbxOUENGMe4i88Ouh+Q21gPQ3HwEgPXVPWO2TWCXJ4YZ2eXsQxsAyH41ZNt1nnqYku6h6yEPSCRjSP9ma8bxD1sBeDJZDsDQOL4ljf1shoPCiOO/r/zc7qy0m9U9rwGQ2/osAOXfnJyQmkPUEEEkhqRevgpAVaIMgEIwXLLd8u63AXgx08sHmS4A3vikBYD8HKvTwbfaAJibSgHw9czvAFj81PsAlE9w7WqIIBJD0m32LanL7bcB2NK/AoCTP8wHILvzTwBSl/sBOF2RprmyAYApfSfstniuw6/UATA3cyGKUkehhggiMWTSsV8AWD9jSfHIdQBqsZ/+P6J94VoeruVHHlu6CIBXK3cAkCA5so/b0TwyUkMEzl/LlCTK7XVjVut5ABY+Ubw/Kd7Btg3OBiCz80Qk/XsTSKLMXqJ7dtkbrkPT2ku2O77q+eLeb9HUEclZH2H8MaRmKgDnlpQ2Y0HXOgCmnz8bbR2Rnv0RxBtDxmLb4CwAZrbYy7K8ZE80aojAC0OS1VXUHewF7i8UhbTvXg7AtN6uWGpRQwReGHJx0zy+nWoXnsMbsMbeZQBM//IiEP3YEaKGCLww5M0Vo5cB+7baW/SK3E+x1qKGCJwaklhgH1w1Z3YBdi7zRb4WgKoOO1cplPrDKGuKuT/vcWJIcv4cABr2fQ9ANjWZv4qPMvd99DoAZYM/uyhNDZHEakgy+wwAf7fakWFt5UDxN4auO08DUHbYjRkhaoggVkPyC+2aR2fddgD++/jq4+1rAaghnjnLWKghglgNub6m9HcMXzrdQE2bWzNC1BCBF4Fc6Uu7LuEeXgTiE7GOIYVfq+3OC3YTrpfO+zQX23rH/6GGCCJ96c5n9KW7B0S/+y9QQwQaiEADEWggAg1EoIEI/gUHN+5F2e9wgQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 72x72 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "tdl.show_batch((x,y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAOcAAAD3CAYAAADmIkO7AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAG2klEQVR4nO3df6jddR3H8c/33jPXjSmKyUzX7I85CQPTpcgUEzX/UIJANMRsQSkts4H065/6L1iSvxpokEpFMMIQpgSWJMqmabFudyQJhkLR3DQyfzGu896vf/lHtfM5+D3n3vPauY8HCOJ753s/4J77jL13z2nati1AnqlxHwA4MnFCKHFCKHFCKHFCKHFCKHFCKHFOgKZp3vyffxaaptkx7nMxnN64D8Dw2rZd896/N02zppRyoJTywPhOxCi4OSfPVaWUl0spu8d9EIYjzsmzpZTy89bfyzzqNf4fTo6maU4rpbxQStnQtu2L4z4Pw3FzTpbrSyl7hDkZxDlZvlBK+dm4D8Fo+G3thGiaZnMp5dFSyslt274x7vMwPDfn5NhSSnlQmJPDzQmh3JwQSpwQSpwQSpwQqvoX3z89dbU/LYIl9ujiA82R/rubE0KJE0KJE0KJE0KJE0KJE0KJE0KJE0KJE0KJE0KJE0KJE0KJE0KJE0KJE0KJE0KJE0KJE0KJE0KJE0KJE0KJE0KJE0KJE0KJE0KJE0KJE0KJE0KJE0KJE0KJE0KJE0KJE0KJE0KJE0KJE0KJE0KJE0KJE0KJE0KJE0KJE0KJE0KJE0KJE0KJE0KJE0KJE0KJE0KJE0KJE0KJE0KJE0KJE0KJE0KJE0KJE0KJE0KJE0KJE0KJE0L1xn2AceitO7U6f+38dct0kv/3ve33V+eXzsxX59NN/dfbhXbxfZ9pVC6Yu6Y6791/YudnH/v869X54txfOz97XNycEEqcEEqcEEqcEEqcEEqcEEqcEGpi95z//M7mvrOZC/9Vfe1TZ9896uOMzKAt5WK7sCzn6GL3Wb+s/4C7uj/7jF/dVJ2fvq37s8fFzQmhxAmhxAmhxAmhxAmhxAmhxAmhYvec71y6qTo/8wf7qvO7T7q172x9b6bTmci148qfVue377quOu89tneEpxkNNyeEEieEEieEEieEEieEEieEEieEit1zzp9QP9ptH356wBPsMleSy2feqs63H1//+ZQYgpsTQokTQokTQokTQokTQokTQiX+CTJD2PTHz1fnOz9R/4jBjauOGeVxGIKbE0KJE0KJE0KJE0KJE0KJE0KJE0LF7jmnDrfV+ezb9Q/D+/fCmr6z2754baczHQ0+8reXqvNb1t9YnS8eM935a//oF/WPTtywanXnZw/ysSe+VJ1vfOy56jzxgxPdnBBKnBBKnBBKnBBKnBBKnBBKnBAqds85s+sP1fl3d53b+dlT5c+dX5vunUE/4MDB6niYX63n2+470mEtvvKB6nzhP68t00lGx80JocQJocQJocQJocQJocQJocQJoWL3nOTZ/63N1fna6T0DntD9p9vON9ZW5x99+HDnZ6dyc0IocUIocUIocUIocUIocUIocUIoe84Vphnw+Zv/+MYn+84e+sqt1dd+aHqm05nes3e+/2znNZdVX7tq396hvnYiNyeEEieEEieEEieEEieEEieEskpZYf7+7f6rklJKmdu6ozIdblVy56sbq/Pfbr2o72xq3+xQX/to5OaEUOKEUOKEUOKEUOKEUOKEUOKEUPacE2bQ21f++ob6t30Ns8t86K0TqvNHtl1cnfd2T963fQ3DzQmhxAmhxAmhxAmhxAmhxAmhxAmh7DnDDHrrykHfjzloj7muN9z3ZNb85HOfqc57s/aY74ebE0KJE0KJE0KJE0KJE0KJE0KJE0LZc47Boc+e13d24Pzp6mufvb72vrKlLOV7y/54tv/7ypZSyhkvvlCdL3Q60crl5oRQ4oRQ4oRQ4oRQ4oRQ4oRQVilLYP6Kc6vzL29/sO/s2mMPjvo4/+V3hz5Ynf/ma5/qO9vw+J+qr7UqGS03J4QSJ4QSJ4QSJ4QSJ4QSJ4QSJ4Sy5+zg8GWbqvP77rmjOl+/hG9POehj+O69+srqfHquvstk+bg5IZQ4IZQ4IZQ4IZQ4IZQ4IZQ4IZQ9ZweX3P5kdb6Ue8zaW1eWUsoj2y6uzntzPobvaOHmhFDihFDihFDihFDihFDihFDihFD2nEew/5ubq/OrjvvhgCes7vy1z7nj5ur85GcOVee93faYk8LNCaHECaHECaHECaHECaHECaHECaHsOY/gzY2Hq/MNq+p7zNm3F6vzr37/631np9z3++prS9vW50wMNyeEEieEEieEEieEEieEEieEWpGrlObsM6vzy8/6y1DPv+nZ66rzE+8dsC6B4uaEWOKEUOKEUOKEUOKEUOKEUOKEUCtyz/nqx4+rzh8+dc8ynQT6c3NCKHFCKHFCKHFCKHFCKHFCKHFCqKb1VosQyc0JocQJocQJocQJocQJocQJod4FCVnk627ueVYAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x,y = torch.add(x,0),torch.add(y,0) #Lose type of tensors (to emulate predictions)\n",
    "test_ne(type(x), TensorImage)\n",
    "tdl.show_batch((x,y), figsize=(4,4)) #Check that types are put back by dl."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: make the above check a proper test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_torch_core.ipynb.\n",
      "Converted 01_layers.ipynb.\n",
      "Converted 02_data.load.ipynb.\n",
      "Converted 03_data.core.ipynb.\n",
      "Converted 04_data.external.ipynb.\n",
      "Converted 05_data.transforms.ipynb.\n",
      "Converted 06_data.block.ipynb.\n",
      "Converted 07_vision.core.ipynb.\n",
      "Converted 08_vision.data.ipynb.\n",
      "Converted 09_vision.augment.ipynb.\n",
      "Converted 09b_vision.utils.ipynb.\n",
      "Converted 09c_vision.widgets.ipynb.\n",
      "Converted 10_tutorial.pets.ipynb.\n",
      "Converted 11_vision.models.xresnet.ipynb.\n",
      "Converted 12_optimizer.ipynb.\n",
      "Converted 13_callback.core.ipynb.\n",
      "Converted 13a_learner.ipynb.\n",
      "Converted 13b_metrics.ipynb.\n",
      "Converted 14_callback.schedule.ipynb.\n",
      "Converted 14a_callback.data.ipynb.\n",
      "Converted 15_callback.hook.ipynb.\n",
      "Converted 15a_vision.models.unet.ipynb.\n",
      "Converted 16_callback.progress.ipynb.\n",
      "Converted 17_callback.tracker.ipynb.\n",
      "Converted 18_callback.fp16.ipynb.\n",
      "Converted 19_callback.mixup.ipynb.\n",
      "Converted 20_interpret.ipynb.\n",
      "Converted 20a_distributed.ipynb.\n",
      "Converted 21_vision.learner.ipynb.\n",
      "Converted 22_tutorial.imagenette.ipynb.\n",
      "Converted 23_tutorial.transfer_learning.ipynb.\n",
      "Converted 30_text.core.ipynb.\n",
      "Converted 31_text.data.ipynb.\n",
      "Converted 32_text.models.awdlstm.ipynb.\n",
      "Converted 33_text.models.core.ipynb.\n",
      "Converted 34_callback.rnn.ipynb.\n",
      "Converted 35_tutorial.wikitext.ipynb.\n",
      "Converted 36_text.models.qrnn.ipynb.\n",
      "Converted 37_text.learner.ipynb.\n",
      "Converted 38_tutorial.ulmfit.ipynb.\n",
      "Converted 40_tabular.core.ipynb.\n",
      "Converted 41_tabular.data.ipynb.\n",
      "Converted 42_tabular.model.ipynb.\n",
      "Converted 43_tabular.learner.ipynb.\n",
      "Converted 45_collab.ipynb.\n",
      "Converted 50_datablock_examples.ipynb.\n",
      "Converted 60_medical.imaging.ipynb.\n",
      "Converted 65_medical.text.ipynb.\n",
      "Converted 70_callback.wandb.ipynb.\n",
      "Converted 71_callback.tensorboard.ipynb.\n",
      "Converted 72_callback.neptune.ipynb.\n",
      "Converted 97_test_utils.ipynb.\n",
      "Converted 99_pytorch_doc.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "from nbdev.export import notebook2script\n",
    "notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "split_at_heading": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
